{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f4fe59",
   "metadata": {},
   "source": [
    "# Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c54e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81eba9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9022132",
   "metadata": {},
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d3d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./processed_objects/features_data.npy', 'rb') as file:\n",
    "    train_data = np.load(file)\n",
    "    val_data = np.load(file)\n",
    "    test_data = np.load(file)\n",
    "\n",
    "with open('./processed_objects/target_data.npy', 'rb') as file:\n",
    "    train_target = np.load(file)\n",
    "    val_target = np.load(file)\n",
    "    test_target = np.load(file)\n",
    "\n",
    "with open('./processed_objects/word_index.pkl', 'rb') as file:\n",
    "    word_index = pickle.load(file)\n",
    "\n",
    "with open('./processed_objects/pretrained_embedding_matrices.npy', 'rb') as file:\n",
    "    pt_fasttext_Matrix = np.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a87dd",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493287f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "\n",
    "\n",
    "def embeddings_to_keras(matrix, max_len, train_embeddings=False):\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=matrix.shape[0],\n",
    "        output_dim=matrix.shape[1],\n",
    "        weights=[matrix],\n",
    "        mask_zero=True,\n",
    "        trainable=train_embeddings\n",
    "    )\n",
    "\n",
    "    return embedding_layer\n",
    "\n",
    "\n",
    "def casefold(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def replace_punctuations(text):\n",
    "    punctuations = set(string.punctuation)\n",
    "    for char in text:\n",
    "        if char in punctuations:\n",
    "            text = text.replace(char, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def clear_emoji(text):\n",
    "    return emoji.replace_emoji(text, ' ')\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize_tokens(word_tokens, word_lemmatizer):\n",
    "    lemmatized_tokens = [word_lemmatizer.lemmatize(\n",
    "        word) for word in word_tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "\n",
    "def remove_stopwords(word_tokens, stopwords_set):\n",
    "    text = ' '.join(\n",
    "        [word for word in word_tokens if word not in stopwords_set])\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_English = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def complete_clean(text):\n",
    "    text = clear_emoji(text)\n",
    "    text = casefold(text)\n",
    "    text = re.sub(r'[0-9]+', ' ', text)\n",
    "    text = text.replace(\"'\", \"'\")\n",
    "    text = text.replace(\"’\", \"'\")\n",
    "    text = text.replace(\"´\", \"'\")\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    text = replace_punctuations(text)\n",
    "    text = tokenize_text(text)\n",
    "    text = lemmatize_tokens(text, word_lemmatizer=lemmatizer)\n",
    "    text = remove_stopwords(text, stopwords_English)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8458f",
   "metadata": {},
   "source": [
    "# Training and Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f0004",
   "metadata": {},
   "source": [
    "## Load Embeddings into Embedding Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db659342",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_fasttext_Embedding = embeddings_to_keras(pt_fasttext_Matrix, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9e677",
   "metadata": {},
   "source": [
    "## Modelling with Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ddc3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    embedding = pt_fasttext_Embedding\n",
    "    recurrent_units = 25\n",
    "\n",
    "    first_dense_units = hp.Int(\n",
    "        'first_dense_units', 16, 512, step=16, default=128)\n",
    "    second_dense_units = hp.Int(\n",
    "        'second_dense_units', 16, 512, step=16, default=64)\n",
    "\n",
    "    optimizer_name = hp.Choice('optimizer',\n",
    "                               values=['adam', 'adamw'],\n",
    "                               default='adam')\n",
    "    learning_rate = hp.Float('learning_rate', 1e-4, 1e-2,\n",
    "                             sampling='log', default=1e-3)\n",
    "    lr_multiplier = hp.Float('lr_multiplier', 0.5, 2.0, default=1.0)\n",
    "\n",
    "    dropout_rate = hp.Float('dropout_rate', 0.2, 0.5,\n",
    "                            step=0.05, default=0.5)\n",
    "\n",
    "    rnn_type = hp.Choice('rnn_type', values=['LSTM', 'GRU'], default='LSTM')\n",
    "    if rnn_type == 'LSTM':\n",
    "        reccurent_layer = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(recurrent_units, return_sequences=False)\n",
    "        )\n",
    "    else:\n",
    "        reccurent_layer = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.GRU(recurrent_units, return_sequences=False)\n",
    "        )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        embedding,\n",
    "        reccurent_layer,\n",
    "        tf.keras.layers.Dense(\n",
    "            first_dense_units, activation='relu'\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            second_dense_units, activation='relu'\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "        tf.keras.layers.Dense(\n",
    "            5, activation='sigmoid'\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    actual_lr = learning_rate * lr_multiplier\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(actual_lr)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.AdamW(actual_lr)\n",
    "\n",
    "    loss_choice = hp.Choice('loss', ['binary_crossentropy', 'focal'],\n",
    "                            default='binary_crossentropy')\n",
    "    if loss_choice == 'focal':\n",
    "        focal_gamma = hp.Float('focal_gamma', 0.5, 3.0, step=0.1, default=2.0)\n",
    "        loss_fn = tf.keras.losses.BinaryFocalCrossentropy(\n",
    "            gamma=focal_gamma, from_logits=False\n",
    "        )\n",
    "    else:\n",
    "        loss_fn = 'binary_crossentropy'\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_fn,\n",
    "        metrics=['binary_accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def print_best_hyperparameters(best_hps):\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    print(f\" - Embedding Type:           pt_fasttext_Embedding\")\n",
    "    print(f\" - Recurrent Units (fixed):  25\")\n",
    "    print(f\" - First Dense Units:        {best_hps.get('first_dense_units')}\")\n",
    "    print(f\" - Second Dense Units:       {best_hps.get('second_dense_units')}\")\n",
    "    print(f\" - Optimizer:                {best_hps.get('optimizer')}\")\n",
    "    print(f\" - Learning Rate:            {best_hps.get('learning_rate')}\")\n",
    "    print(f\" - LR Multiplier:            {best_hps.get('lr_multiplier')}\")\n",
    "\n",
    "    print(f\" - RNN Type:                 {best_hps.get('rnn_type')}\")\n",
    "    print(f\" - Loss Function:            {best_hps.get('loss')}\")\n",
    "    if best_hps.get('loss') == 'focal':\n",
    "        print(f\"    • Focal Gamma:           {best_hps.get('focal_gamma')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46117eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6631893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data\n",
    "X_val = val_data\n",
    "X_test = test_data\n",
    "\n",
    "Y_train = train_target\n",
    "Y_val = val_target\n",
    "Y_test = test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9e25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"binary_accuracy\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='nn_multilabel'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b61506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      " - Embedding Type:           pt_fasttext_Embedding\n",
      " - Recurrent Units (fixed):  25\n",
      " - First Dense Units:        32\n",
      " - Second Dense Units:       272\n",
      " - Optimizer:                adam\n",
      " - Learning Rate:            0.0054986817452001\n",
      " - LR Multiplier:            1.2170614207934312\n",
      " - RNN Type:                 LSTM\n",
      " - Loss Function:            focal\n",
      "    • Focal Gamma:           1.5\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train, epochs=20, validation_data=(\n",
    "    X_test, Y_test), callbacks=[stop_early])\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "print_best_hyperparameters(best_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6b140",
   "metadata": {},
   "source": [
    "# Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f406d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class val_accuracy_Callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_binary_accuracy') >= 0.94:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85af4ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_Callback = val_accuracy_Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd9c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "765a218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - binary_accuracy: 0.9904 - loss: 0.0111 - val_binary_accuracy: 0.9352 - val_loss: 0.1220\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - binary_accuracy: 0.9935 - loss: 0.0074 - val_binary_accuracy: 0.9367 - val_loss: 0.1466\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - binary_accuracy: 0.9957 - loss: 0.0051 - val_binary_accuracy: 0.9364 - val_loss: 0.1637\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - binary_accuracy: 0.9936 - loss: 0.0076 - val_binary_accuracy: 0.9341 - val_loss: 0.1714\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - binary_accuracy: 0.9940 - loss: 0.0073 - val_binary_accuracy: 0.9391 - val_loss: 0.1547\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - binary_accuracy: 0.9939 - loss: 0.0076 - val_binary_accuracy: 0.9391 - val_loss: 0.1513\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - binary_accuracy: 0.9957 - loss: 0.0047 - val_binary_accuracy: 0.9357 - val_loss: 0.1723\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - binary_accuracy: 0.9939 - loss: 0.0082 - val_binary_accuracy: 0.9327 - val_loss: 0.1636\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - binary_accuracy: 0.9963 - loss: 0.0045 - val_binary_accuracy: 0.9331 - val_loss: 0.1588\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - binary_accuracy: 0.9966 - loss: 0.0042 - val_binary_accuracy: 0.9393 - val_loss: 0.1644\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - binary_accuracy: 0.9976 - loss: 0.0028 - val_binary_accuracy: 0.9347 - val_loss: 0.1619\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - binary_accuracy: 0.9960 - loss: 0.0051 - val_binary_accuracy: 0.9373 - val_loss: 0.1923\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - binary_accuracy: 0.9966 - loss: 0.0045 - val_binary_accuracy: 0.9385 - val_loss: 0.1683\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - binary_accuracy: 0.9960 - loss: 0.0052 - val_binary_accuracy: 0.9318 - val_loss: 0.1868\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - binary_accuracy: 0.9978 - loss: 0.0034 - val_binary_accuracy: 0.9366 - val_loss: 0.1856\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - binary_accuracy: 0.9962 - loss: 0.0052 - val_binary_accuracy: 0.9311 - val_loss: 0.2073\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - binary_accuracy: 0.9955 - loss: 0.0069 - val_binary_accuracy: 0.9347 - val_loss: 0.1904\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - binary_accuracy: 0.9967 - loss: 0.0041 - val_binary_accuracy: 0.9386 - val_loss: 0.1962\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - binary_accuracy: 0.9959 - loss: 0.0065 - val_binary_accuracy: 0.9346 - val_loss: 0.1711\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - binary_accuracy: 0.9982 - loss: 0.0027 - val_binary_accuracy: 0.9352 - val_loss: 0.2030\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21929e089b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, Y_train, epochs=50, validation_data=(\n",
    "    X_test, Y_test), callbacks=[val_acc_Callback, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2786ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 0.9322 - loss: 0.1786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1643703132867813, 0.9392739534378052]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ecb12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,446,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,365</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m300\u001b[0m)          │     \u001b[38;5;34m1,446,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │        \u001b[38;5;34m65,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │         \u001b[38;5;34m1,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m272\u001b[0m)              │         \u001b[38;5;34m8,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m272\u001b[0m)              │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m272\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)                │         \u001b[38;5;34m1,365\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,680,297</span> (6.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,680,297\u001b[0m (6.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,717</span> (303.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,717\u001b[0m (303.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,447,144</span> (5.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,447,144\u001b[0m (5.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,436</span> (607.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m155,436\u001b[0m (607.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48643b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"./model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2cffe9",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b95b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"DBS app is soo good!!\", \"Give me back my moneyy 🔥🔥\", \"They stole my money\",\n",
    "             \"They are generous\", \"So many promo\", \"The app is so bad!!!\", \"app is terrible\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b755dcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\emoji\\tokenizer.py:180: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  char = string[i]\n"
     ]
    }
   ],
   "source": [
    "cleaned_sentences = pd.DataFrame(sentences, columns=[\"sentence\"]).apply(\n",
    "    complete_clean, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c741f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.word_index = word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5f5cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentences = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(\n",
    "    cleaned_sentences.tolist()), truncating=\"post\", padding='post').astype(float, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ded6d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Neutral\",\n",
    "    2: \"Positive\",\n",
    "    3: \"Very Negative\",\n",
    "    4: \"Very Positive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "098d39e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step\n"
     ]
    }
   ],
   "source": [
    "results = np.argmax(best_model.predict(padded_sentences), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a35e0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBS app is soo good!!: Positive\n",
      "Give me back my moneyy 🔥🔥: Neutral\n",
      "They stole my money: Neutral\n",
      "They are generous: Neutral\n",
      "So many promo: Neutral\n",
      "The app is so bad!!!: Neutral\n",
      "app is terrible: Negative\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    print(f\"{sentences[i]}: {label_map[results[i]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
